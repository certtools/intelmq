#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Implemented workarounds for Python 2.6, postgres 9.1 and old debian packages:
    own table_from_query() instead of prettytable.from_csv()
    postgres to_char(time.source, 'TZ') instead of 'OF' (from 9.4 up)
        This gives the timezone instead of the offset (empty if UTC)
    BytesIO instead of StringIO on Python 2 for csv module

TODO: "feed.name" ILIKE '%' is slow
"""
from __future__ import print_function, unicode_literals

import argparse
import csv
import datetime
import io
import json
import locale
import os
import pprint
import subprocess
import sys
import tempfile
import zipfile
import six

import prettytable
import psycopg2
import psycopg2.extras
from termstyle import bold, green, inverted, red, reset

import rt

""" options """
dryrun = False
verbose = False
compress_csv = False
boilerplate=None



if locale.getpreferredencoding() != 'UTF-8':
    print(red('The preferred encoding of your locale setting is not UTF-8 but'
              '{}. Exiting.'.format(locale.getpreferredencoding())))
    exit(1)

myinverted = str(reset) + str(inverted)
if sys.version[0] == '2':
    input = raw_input

CONFIG = dict()
home = os.path.expanduser("~")      # needed for OSX
with open(os.path.expanduser(home + '/.intelmq/intelmqcli.conf')) as conf_handle:
    user_config = json.load(conf_handle)
with open('/etc/intelmq/intelmqcli.conf') as conf_handle:
    CONFIG = json.load(conf_handle)

for key, value in user_config.items():
    if key in CONFIG and type(CONFIG[key]) is dict:
        CONFIG[key].update(value)
    else:
        CONFIG[key] = value

APPNAME = "intelmqcli"
DESCRIPTION = """
"""
EPILOG = """
Searches for all unprocessed incidents. Incidents will be filtered by country
code and the TLD of a domain according to configuration.
The search can be restricted to one source feed.

After the start, intelmqcli will immediately connect to RT with the given
credentials. The incidents will be shown grouped by the contact address if
known or the ASN otherwise.

You have 3 options here:
* Select one group by giving the id (number in first column) and show the email
and all events in detail
* Automatic sending of all incidents with 'a'
* Quit with 'q'

For the detailed view, the recipient, the subject and the mail text will be
shown, and below the technical data as csv. If the terminal is not big enough,
the data will not be shown in full. In this case, you can press 't' for the
table mode. less will be opened with the full text and data, whereas the data
will be formated as table, which is much easier to read and interpret.
The requestor (recipient of the mail) can be changed manually by pressing 'r'
and in the following prompt the address is asked. After sending, you can
optionally save the (new) address to the database linked to the ASNs.
If you are ready to submit the incidents to RT and send the mails out, press
's'.
'b' for back jumps to the incident overview and 'q' quits.
"""
USAGE = '''
    intelmqcli
    intelmqcli --dry-run
    intelmqcli --verbose
    intelmqcli --compress-csv
    intelmqcli --list-feeds
    intelmqcli --list-texts
    intelmqcli --text='boilerplate name'
    intelmqcli --feed='feedname' '''

CON = psycopg2.connect(database=CONFIG['database']['database'],
                       user=CONFIG['database']['user'],
                       password=CONFIG['database']['password'],
                       host=CONFIG['database']['host'],
                       port=CONFIG['database']['port'],
                       sslmode=CONFIG['database']['sslmode'],
                       )
CUR = CON.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
CON.autocommit = True

RT = rt.Rt(CONFIG['rt']['uri'], CONFIG['rt']['user'], CONFIG['rt']['password'])
TABLE_MODE = False  # for sticky table mode

QUERY_COUNT_ASN = """
SELECT
    COUNT(*) as count,
    COALESCE({conttab}.contacts, '') as contacts,
    string_agg(DISTINCT cast({evtab}."source.asn" as varchar), ', ') as asn,
    string_agg(DISTINCT {evtab}."classification.type", ', ') as classification,
    string_agg(DISTINCT {evtab}."feed.code", ', ') as feeds,
    COALESCE({conttab}.contacts, cast({evtab}."source.asn" as varchar))
        as grouping
FROM {evtab}
LEFT OUTER JOIN as_contacts ON {evtab}."source.asn" = {conttab}.asnum
WHERE
    notify = TRUE AND (
        {evtab}.rtir_report_id IS NULL OR
        {evtab}.rtir_incident_id IS NULL OR
        {evtab}.rtir_investigation_id IS NULL
    )
    AND
    (
        {evtab}."source.geolocation.cc" LIKE '{cc}' OR
        {evtab}."source.fqdn" LIKE %s
    )
    AND "feed.name" ILIKE %s AND
    "time.source" IS NOT NULL
GROUP BY {conttab}.contacts, grouping;
""".format(evtab=CONFIG['database']['events_table'], cc=CONFIG['filter']['cc'],
           conttab=CONFIG['database']['contacts_table'])

""" This is the list of fields (and their respective order) which we intend to
send out.  This is based on the order and fields of shadowserver. 

Shadowserver format:
    timestamp,"ip","protocol","port","hostname","packets","size","asn","geo","region","city","naics","sic","sector"
"""

CSV_FIELDS=["time.source", "source.ip", "protocol.transport", "source.port", "protocol.application",
            "source.fqdn", "source.local_hostname", "source.local_ip", "source.url",
            "source.asn", "source.geolocation.cc",
            "source.geolocation.city",
            "classification.taxonomy", "classification.type", "classification.identifier",
            "destination.ip","destination.port","destination.fqdn","destination.url",
            "feed", "event_description.text","event_description.url","malware.name","comment", "additional_field_freetext","version: 1.0"
           ]

QUERY_BY_ASCONTACT = """
SELECT
    to_char({evtab}."time.source",
            'YYYY-MM-DD"T"HH24:MI:SS"+00"') as "time.source",
    {evtab}.id,
    {evtab}."feed.code" as feed,
    {evtab}."source.ip",
    {evtab}."source.port",
    {evtab}."source.asn",
    {evtab}."source.network",
    {evtab}."source.geolocation.cc",
    {evtab}."source.geolocation.region",
    {evtab}."source.geolocation.city",
    {evtab}."source.account",
    {evtab}."source.fqdn",
    {evtab}."source.local_hostname",
    {evtab}."source.local_ip",
    {evtab}."source.reverse_dns",
    {evtab}."source.tor_node",
    {evtab}."source.url",
    {evtab}."classification.identifier",
    {evtab}."classification.taxonomy",
    {evtab}."classification.type",
    {evtab}."comment",
    {evtab}."destination.ip",
    {evtab}."destination.port",
    {evtab}."destination.asn",
    {evtab}."destination.network",
    {evtab}."destination.geolocation.cc",
    {evtab}."destination.geolocation.region",
    {evtab}."destination.geolocation.city",
    {evtab}."destination.account",
    {evtab}."destination.fqdn",
    {evtab}."destination.local_hostname",
    {evtab}."destination.local_ip",
    {evtab}."destination.reverse_dns",
    {evtab}."destination.tor_node",
    {evtab}."destination.url",
    {evtab}."event_description.target",
    {evtab}."event_description.text",
    {evtab}."event_description.url",
    {evtab}."event_hash",
    {evtab}."extra",
    {evtab}."feed.accuracy",
    {evtab}."malware.hash",
    {evtab}."malware.hash.md5",
    {evtab}."malware.hash.sha1",
    {evtab}."malware.name",
    {evtab}."malware.version",
    {evtab}."misp_uuid",
    {evtab}."notify",
    {evtab}."protocol.application",
    {evtab}."protocol.transport",
    {evtab}."screenshot_url",
    {evtab}."status",
    {evtab}."time.observation"
FROM events
LEFT OUTER JOIN {conttab} ON {evtab}."source.asn" = {conttab}.asnum
WHERE
    notify = TRUE AND (
        {evtab}.rtir_report_id IS NULL OR
        {evtab}.rtir_incident_id IS NULL OR
        {evtab}.rtir_investigation_id IS NULL
    ) AND
    {conttab}.contacts = %s AND
    "feed.name" ILIKE %s AND
    "time.source" IS NOT NULL;
""".format(evtab=CONFIG['database']['events_table'],
           conttab=CONFIG['database']['contacts_table'])

QUERY_BY_ASNUM = """
SELECT
    to_char({evtab}."time.source" at time zone 'UTC',
            'YYYY-MM-DD"T"HH24:MI:SS"+00"') as "time.source",
    {evtab}.id,
    {evtab}."feed.code" as feed,
    {evtab}."source.ip",
    {evtab}."source.port",
    {evtab}."source.asn",
    {evtab}."source.network",
    {evtab}."source.geolocation.cc",
    {evtab}."source.geolocation.region",
    {evtab}."source.geolocation.city",
    {evtab}."source.account",
    {evtab}."source.fqdn",
    {evtab}."source.local_hostname",
    {evtab}."source.local_ip",
    {evtab}."source.reverse_dns",
    {evtab}."source.tor_node",
    {evtab}."source.url",
    {evtab}."classification.identifier",
    {evtab}."classification.taxonomy",
    {evtab}."classification.type",
    {evtab}."comment",
    {evtab}."destination.ip",
    {evtab}."destination.port",
    {evtab}."destination.asn",
    {evtab}."destination.network",
    {evtab}."destination.geolocation.cc",
    {evtab}."destination.geolocation.region",
    {evtab}."destination.geolocation.city",
    {evtab}."destination.account",
    {evtab}."destination.fqdn",
    {evtab}."destination.local_hostname",
    {evtab}."destination.local_ip",
    {evtab}."destination.reverse_dns",
    {evtab}."destination.tor_node",
    {evtab}."destination.url",
    {evtab}."event_description.target",
    {evtab}."event_description.text",
    {evtab}."event_description.url",
    {evtab}."event_hash",
    {evtab}."extra",
    {evtab}."feed.accuracy",
    {evtab}."malware.hash",
    {evtab}."malware.hash.md5",
    {evtab}."malware.hash.sha1",
    {evtab}."malware.name",
    {evtab}."malware.version",
    {evtab}."misp_uuid",
    {evtab}."notify",
    {evtab}."protocol.application",
    {evtab}."protocol.transport",
    {evtab}."screenshot_url",
    {evtab}."status",
    {evtab}."time.observation"
FROM events
LEFT OUTER JOIN {conttab} ON {evtab}."source.asn" = {conttab}.asnum
WHERE
    notify = TRUE AND (
        {evtab}.rtir_report_id IS NULL OR
        {evtab}.rtir_incident_id IS NULL OR
        {evtab}.rtir_investigation_id IS NULL
    ) AND
    {evtab}."source.asn" = %s AND
    "feed.name" ILIKE %s AND
    "time.source" IS NOT NULL;
""".format(evtab=CONFIG['database']['events_table'],
           conttab=CONFIG['database']['contacts_table'])


QUERY_SET_RTIRID = """
UPDATE {evtab} SET
    rtir_{{type}}_id = {{rtirid}},
    sent_at = LOCALTIMESTAMP
WHERE
    id = ANY('{{{{{{ids}}}}}}'::int[]);
""".format(evtab=CONFIG['database']['events_table'])

QUERY_UPDATE_CONTACT = """
UPDATE {conttab} SET
    contacts = '{{contacts}}'
WHERE
    asnum = ANY('{{{{{{asns}}}}}}'::int[]);
""".format(conttab=CONFIG['database']['contacts_table'])

QUERY_INSERT_CONTACT = """
INSERT INTO {conttab} (
    asnum, contacts, comment, unreliable
) VALUES (
    %s, %s, %s, FALSE
)
""".format(conttab=CONFIG['database']['contacts_table'])

QUERY_GET_TEXT = """
SELECT
    body
FROM {texttab}
WHERE
    key = %s
""".format(texttab=CONFIG['database']['text_table'])

QUERY_FEED_NAMES = "SELECT DISTINCT \"feed.name\" from events"

QUERY_TEXT_NAMES = "SELECT DISTINCT \"key\" from boilerplates"


def get_text(query):
    types = [row['classification.identifier'] for row in query
             if 'classification.identifier' in row]
    text = None
    if boilerplate:
        text_id = boilerplate
    else:
        text_id = types[0]
    if len(types) == 1:
        CUR.execute(QUERY_GET_TEXT, (text_id, ))
        if CUR.rowcount:
            text = CUR.fetchall()[0]['body']

    if text is None and boilerplate:
        return red('--text param given, but boilerplate text %s not found!' %text_id)

    if text is None:
        CUR.execute(QUERY_GET_TEXT, (CONFIG['database']['default_key'], ))
        if CUR.rowcount:
            text = CUR.fetchall()[0]['body']
        else:
            return red('Default text not found!')

    return text


def target_from_row(row):
    """
    Returns the first value in give row that exists from this list of keys:
    'source.ip', 'source.fqdn', 'source.url', 'source.account'
    """
    keys = ['source.ip', 'source.fqdn', 'source.url', 'source.account']
    for key in keys:
        if key in row:
            return row[key]


def table_from_query(query):
    header = sorted(query[0].keys())
    table = prettytable.PrettyTable(header)
    for row in query:
        table.add_row([row[key] for key in header])
    return table


def shrink_dict(d):
    if not compress_csv:
        return d
    keys = d[0].keys()
    empty = dict(zip(keys, [True] * len(keys)))
    for line in d:
        for key, value in line.items():
            if value is not None:
                empty[key] = False
    return [{k: v for k, v in dicti.items() if not empty[k]} for dicti in d]


def getTerminalHeight():
    return int(subprocess.check_output(['stty', 'size']).strip().split()[0])


def query_by_as(contact, requestor=None, automatic=False, feed='%'):
    if type(contact) is int:
        CUR.execute(QUERY_BY_ASNUM, (contact, feed))
        if requestor is None:
            requestor = ''
    else:
        CUR.execute(QUERY_BY_ASCONTACT, (contact, feed))
        if requestor is None:
            requestor = contact
    query = shrink_dict(CUR.fetchall())
    ids = list(str(row['id']) for row in query)
    asns = set(str(row['source.asn']) for row in query)

    subject = ('{date}: {count} incidents for your AS {asns}'
               ''.format(count=len(query),
                         date=datetime.datetime.now().strftime('%Y-%m-%d'),
                         asns=', '.join(asns)))
    text = get_text(query)
    if sys.version_info[0] == 2:
        csvfile = io.BytesIO()
    else:
        csvfile = io.StringIO()
    if CSV_FIELDS:
        fieldnames=CSV_FIELDS
    else:
        fieldnames=(query[0].keys())    # send all
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, 
                            extrasaction='ignore', lineterminator='\n')
    writer.writeheader()
    writer.writerows(query)
    attachment_text = csvfile.getvalue()
    attachment_lines = attachment_text.splitlines()

    if verbose:
        pprint.pprint(text)

    showed_text = '=' * 100 + '''
To: {to}
Subject: {subj}

{text}
'''.format(to=requestor, subj=subject, text=six.text_type(text, encoding='utf8', errors='ignore'))
    showed_text_len = showed_text.count('\n')

    global TABLE_MODE
    if TABLE_MODE:
        height = getTerminalHeight() - 3 - showed_text_len
        csvfile.seek(0)
        if len(query) > height:
            with tempfile.NamedTemporaryFile(mode='w+') as handle:
                handle.write(showed_text + '\n')
                try:
                    handle.write(str(prettytable.from_csv(csvfile)))
                except AttributeError:
                    handle.write(str(table_from_query(query)))
                handle.seek(0)
                subprocess.call(['less', handle.name])
        else:
            try:
                print(showed_text, prettytable.from_csv(csvfile), sep='\n')
            except AttributeError:
                print(showed_text, table_from_query(query), sep='\n')
    else:
        height = getTerminalHeight() - 4
        if 5 + len(query) > height:  # cut query too, 5 is length of text
            print('\n'.join(showed_text.splitlines()[:5]))
            print('...')
            print('\n'.join(attachment_lines[:height - 5]))
            print('...')
        elif showed_text_len + len(query) > height > 5 + len(query):
            print('\n'.join(showed_text.splitlines()[:height - len(query)]))
            print('...')
            print(attachment_text)
        else:
            print(showed_text, attachment_text, sep='\n')
    print('-' * 100)
    if automatic and requestor:
        answer = 's'
    else:
        if automatic:
            print(red('You need to set a valid requestor!'))
        answer = input('{i}{b}[b]{i}ack, {b}[s]{i}end, show {b}[t]{i}able, '
                       'change {b}[r]{i}equestor or {b}[q]{i}uit?{r} '
                       ''.format(b=bold, i=myinverted, r=reset)).strip()
    if answer == 'q':
        exit(0)
    elif answer == 'b':
        return
    elif answer == 't':
        TABLE_MODE = bool((TABLE_MODE + 1) % 2)
        query_by_as(contact, requestor=requestor, feed=feed)
        return
    elif answer == ('r'):
        answer = input(inverted('New requestor address:') + ' ').strip()
        if len(answer) == 0:
            if type(contact) is int:
                requestor = ''
            else:
                requestor = contact
        else:
            requestor = answer
        query_by_as(contact, requestor=requestor, feed=feed)
        return
    elif answer != 's':
        print(red('Unknow command {!r}.'.format(answer)))
        query_by_as(contact, requestor=requestor, feed=feed)
        return

    # TODO: Config option for single events (best in ascontacts db)
    if text.startswith(str(red)):
        print(red('I won\'t send with a missing text!'))
        return
    if True:
        save_to_rt(ids=ids, subject=subject, requestor=requestor,
                   csvfile=csvfile, body=text)
    else:
        header = attachment_lines[0]
        for id_, attach_line, row in zip(ids, attachment_lines[1:], query):
            if sys.version_info[0] == 2:
                csvfile = io.BytesIO()
            else:
                csvfile = io.StringIO()
            csvfile.write(header + str('\n'))
            csvfile.write(attach_line)
            subj_date = datetime.datetime.now().strftime('%Y-%m-%d')
            subject = ('{date}: Incident {type} for {target}'
                       ''.format(count=len(query),
                                 date=subj_date,
                                 type=row['classification.type'],
                                 target=target_from_row(row)))
            save_to_rt(ids=(id_, ), subject=subject, requestor=requestor,
                       csvfile=csvfile, body=text)

    if requestor != contact and not dryrun:
        answer = input(inverted('Save recipient {!r} for ASNs {!s}? [Y/n]'
                                ''.format(requestor, ', '.join(asns)))).strip()
        if answer.lower() in ('', 'y', 'j'):
            CUR.execute(QUERY_UPDATE_CONTACT.format(asns=','.join(asns),
                                                    contacts=requestor))
            if CUR.rowcount != 1:
                for asn in asns:
                    user = os.environ['USER']
                    time = datetime.datetime.now().strftime('%c')
                    comment = 'Added by {user} @ {time}'.format(user=user,
                                                                time=time)
                    CUR.execute(QUERY_INSERT_CONTACT, (int(asn), requestor,
                                                       comment))


def save_to_rt(ids, subject, requestor, csvfile, body):
    if dryrun:
        print('Not writing to RT, dry-run selected.')
        return

    b = six.text_type(body, encoding='utf8', errors='ignore')
    body = b

    report_id = RT.create_ticket(Queue='Incident Reports', Subject=subject,
                                 Owner=CONFIG['rt']['user'])
    if report_id == -1:
        print(red('Could not create Incident Report.'))
        return
    print(green('Created Incident Report {}.'.format(report_id)))
    CUR.execute(QUERY_SET_RTIRID.format(ids=','.join(ids), rtirid=report_id,
                                        type='report'))
    if True:  # TODO: implement zip config
        attachment = csvfile
        attachment.seek(0)
        filename = 'events.csv'
    else:
        attachment = io.BytesIO()
        ziphandle = zipfile.ZipFile(attachment, mode='w')
        ziphandle.writestr('events.csv', csvfile.getvalue())
        ziphandle.close()
        attachment.seek(0)
        filename = 'events.zip'

    incident_id = RT.create_ticket(Queue='Incidents', Subject=subject,
                                   Owner=CONFIG['rt']['user'])
    if incident_id == -1:
        print(red('Could not create Incident.'))
        return
    print(green('Created Incident {}.'.format(incident_id)))
    if not RT.edit_link(report_id, 'MemberOf', incident_id):
        print(red('Could not link Incident to Incident Report.'))
        return
    CUR.execute(QUERY_SET_RTIRID.format(ids=','.join(ids), rtirid=incident_id,
                                        type='incident'))
    investigation_id = RT.create_ticket(Queue='Investigations',
                                        Subject=subject,
                                        Owner=CONFIG['rt']['user'],
                                        Requestor=requestor)
    if investigation_id == -1:
        print(red('Could not create Investigation.'))
        return
    print(green('Created Investigation {}.'.format(investigation_id)))
    if not RT.edit_link(incident_id, 'HasMember', investigation_id):
        print(red('Could not link Investigation to Incident.'))
        return

    # TODO: CC
    correspond = RT.reply(investigation_id, text=body,
                          files=[(filename, attachment)])
    if not correspond:
        print(red('Could not correspond with text and file.'))
        return
    print(green('Correspondence added to Investigation.'))

    CUR.execute(QUERY_SET_RTIRID.format(ids=','.join(ids),
                                        rtirid=investigation_id,
                                        type='investigation'))
    if not RT.edit_ticket(incident_id, Status='resolved'):
        print(red('Could not close incident {}.'.format(incident_id)))


def count_by_asn(feed='%'):
    # TODO: Existing RT ids!
    CUR.execute(QUERY_COUNT_ASN, (CONFIG['filter']['fqdn'], feed))
    asn_count = CUR.fetchall()
    if not asn_count:
        print('No incidents!')
        exit(0)
    asn_len = [len(row['asn']) for row in asn_count if row['asn']]
    max_asn_length = max(asn_len) if asn_len else 10
    contact_len = [len(row['contacts']) for row in asn_count if row['contacts']]
    max_contact_length = max(contact_len) if contact_len else 10
    class_len = [len(row['classification']) for row in asn_count if
                    row['classification']]
    max_class_length = max(class_len) if class_len else 10
    print('=' * 100)
    print(bold("{id:>3} {count:3} {asn!s: <{asnlen}} {contacts!s: <{conlen}} "
               "{type!s: <{typelen}} feeds"
               "".format(id='id', count='nÂ°', asn='ASNs', type='types',
                         conlen=max_contact_length,
                         asnlen=max_asn_length, contacts='contacts',
                         typelen=max_class_length)))
    for number, row in enumerate(asn_count):
        print("{id:>3} {count:3} {asn!s: <{asnlen}} {contacts!s: <{conlen}} "
              "{type!s: <{typelen}} {feeds}"
              "".format(count=row['count'], asn=row['asn'],
                        asnlen=max_asn_length, id=number,
                        contacts=row['contacts'],
                        conlen=max_contact_length,
                        type=row['classification'], typelen=max_class_length,
                        feeds=row['feeds']))
    print('{} incidents for {} contacts.'
          ''.format(sum((row['count'] for row in asn_count)), len(asn_count)))
    return asn_count

if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        prog=APPNAME,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        usage=USAGE,
        description=DESCRIPTION,
        epilog=EPILOG,
    )
    parser.add_argument('-l', '--list-feeds', action='store_true',
                        help='List all feeds')
    parser.add_argument('-L', '--list-texts', action='store_true',
                        help='List all existing texts.')
    parser.add_argument('-t', '--text', nargs=1, help='Specify the text to be used.')
    parser.add_argument('-f', '--feed', nargs='?', default='%', const='%',
                        help='Show only incidents reported by given feed.')
    parser.add_argument('-v', '--verbose', action='store_true',
                        help='Print verbose messages.')
    parser.add_argument('-c', '--compress-csv', action='store_true',
                        help='Automatically compress/shrink the attached CSV report if fields are empty (default = False).')
    parser.add_argument('-n', '--dry-run', action='store_true',
                        help='Do not store anything or change anything. Just simulate.')
    args = parser.parse_args()

    if args.verbose:
        verbose = True
    if args.dry_run:
        dryrun = True
    if args.compress_csv:
        compress_csv = True
    if args.text:
        boilerplate = args.text

    if args.list_feeds:
        CUR.execute(QUERY_FEED_NAMES)
        for row in CUR.fetchall():
            if row['feed.name']:
                print(row['feed.name'])
        exit(0)

    if args.list_texts:
        CUR.execute(QUERY_TEXT_NAMES)
        for row in CUR.fetchall():
            if row['key']:
                print(row['key'])
        exit(0)

    if not RT.login():
        print(red('Could not login as {} on {}.'.format(CONFIG['rt']['user'],
                                                        CONFIG['rt']['uri'])))
    else:
        print('Logged in as {} on {}.'.format(CONFIG['rt']['user'],
                                              CONFIG['rt']['uri']))
    try:
        while True:
            asn_count = count_by_asn(feed=args.feed)
            if verbose:
                print(sys.stderr, 'asn_count = {}.'.format(asn_count))
            answer = input('{i}detailed view by id, {b}[a]{i}utomatic '
                           'sending, {b}[q]{i}uit?{r} '
                           ''.format(b=bold, i=myinverted, r=reset)).strip()
            try:
                answer = int(answer)
            except ValueError:
                pass
            if answer == 'q':
                break
            elif answer == 'a':
                for item in asn_count:
                    if item['contacts']:
                        query_by_as(item['contacts'], automatic=True,
                                    feed=args.feed)
                    else:
                        if item['asn']:
                            query_by_as(int(item['asn']), automatic=True,
                                        feed=args.feed)
                        else:
                            print(red('Can not query the data of an unknown ASN. Ignoring.'))
            elif type(answer) is int:
                if asn_count[answer]['contacts']:
                    query_by_as(asn_count[answer]['contacts'], feed=args.feed)
                else:
                    if asn_count[answer] and asn_count[answer]['asn']:
                        query_by_as(int(asn_count[answer]['asn']), feed=args.feed)
                    else:
                        print(red('no ASNs known. Ignoring.'))
            else:
                print(red('Unknown answer {!r}.'.format(answer)))

    except BaseException as exc:
        if isinstance(exc, (SystemExit, KeyboardInterrupt)):
            print()
        else:
            raise
    finally:
        RT.logout()
